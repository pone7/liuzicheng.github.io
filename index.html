<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Zicheng Liu, 刘梓丞, machine learning, westlake university, zhejiang university">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/westlake.ico">
<title>Zicheng Liu</title>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./" style="color:#2a7ce0"><img src="./Files/zichengliu.jpg" alt="" height="215px" /></a>&nbsp;</td>
<td align="left"><p><a href="./" style="color:#2a7ce0"><font size="4">Zicheng Liu (</font><font size="4"; font style="font-family:Microsoft YaHei">刘梓丞</font><font size="4">)</font></a><br />
<i>Ph.D Candidate </i>
<br /><br />
<a href="https://www.westlake.edu.cn/" target="_blank" style="color:#2a7ce0">Center for Artificial Intelligence Research and Innovation (CAIRI)</a><br />
<a href="https://www.westlake.edu.cn/" target="_blank" style="color:#2a7ce0">Westlake University</a><br />
<br />
Location: Building 2-Room 508, Shilongshan Street #18, Xihu District, Hangzhou, Zhejiang, China<br />
<class="staffshortcut">
 <A HREF="#News" style="color:#2a7ce0">News</A> | 
 <A HREF="#Interest" style="color:#2a7ce0">Research Interest</A> | 
 <A HREF="#Education" style="color:#2a7ce0">Education</A> | 
 <A HREF="#Publications" style="color:#2a7ce0">Publications</A> | 
 <A HREF="#Services" style="color:#2a7ce0">Services</A> | 
 <!-- <A HREF="#Awards" style="color:#2a7ce0">Awards</A> -->
<br />
<br />
 
Email: liuzicheng@westlake.edu.cn <br />
[<a href="https://scholar.google.com/citations?user=EwMGZsgAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Google Scholar</a>] 
[<a href="https://github.com/pone7" target="_blank" style="color:#2a7ce0">GitHub</a>] 
<!-- [<a href="https://www.researchgate.net/profile/Lirong-Wu-2" target="_blank" style="color:#2a7ce0">ResearchGate</a>] 
[<a href="https://orcid.org/0000-0001-5551-3194" target="_blank" style="color:#2a7ce0">ORCID</a>]  -->
</td></tr></table>




<A NAME="News"><h2>News</h2></A>
<ul>
<li><b> <font color="#FF0000">[2022.07]</font> </b> One paper (<b>Oral</b>) on <i>data augmentation</i> has been accepted by <b>ECCV2022</b>. </li>
<li><b> <font color="#FF0000">[2022.01]</font> </b> Open source a toolbox, <i><a href="https://github.com/Westlake-AI/openmixup"> openmixup</a></i>, for supervised, self- and semi-unsupervised representation learning based on PyTorch, especially for mixup-related methods, many thanks to <a href="https://scholar.google.com/citations?user=SKTQTXwAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Siyuan Li</a> for his great contribution. </li>
<!-- <li><b> <font color="#FF0000">[2022.03]</font> </b> One paper on <i>video prediction</i> has been accepted by <b>CVPR 2022</b>, congrats to <a href="https://scholar.google.com/citations?hl=zh-CN&user=4SclT-QAAAAJ" target="_blank" style="color:#2a7ce0">Zhangyang Gao</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2022.03]</font> </b> One paper on <i>semi-supervised learning</i> has been accepted by <b>CVPR 2022</b>, congrats to <a href="https://scholar.google.com/citations?user=6kTV6aMAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Cheng Tan</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2022.02]</font> </b> One paper on <i>label denoising</i> has been accepted by <b>ICASSP 2022</b>, congrats to <a href="https://scholar.google.com/citations?user=aPKKpSYAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Jun Xia</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2022.02]</font> </b> One paper on <i>deep clustering</i> has been accepted by <b>WACV2022</b>. </li> -->
<!-- <li><b> <font color="#FF0000">[2022.01]</font> </b> One paper on <i>graph contrastive learning</i> has been accepted by <b>WWW 2022</b>, congrats to <a href="https://scholar.google.com/citations?user=aPKKpSYAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Jun Xia</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2022.01]</font> </b> One paper on <i>disentanglement learning</i> has been accepted by <b>NCAA</b>. </li> -->

<!-- <li><b> <font color="#FF0000">[2021.12]</font> </b> One paper on <i>spatio-temporal forecasting</i> has been accepted by <b>AAAI 2022</b>, congrats to <a href="https://scholar.google.com/citations?user=o5A23qIAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Haitao Lin</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2021.11]</font> </b> One paper on <i>graph self-supervised learning</i> has been accepted by <b>TKDE</b>. </li> -->
<li><b> <font color="#FF0000">[2021.10]</font> </b> One paper on <i>deep clustering</i> has been accepted by <b>WACV2022</b>, congrats to <a href="https://scholar.google.com/citations?user=EwMGZsgAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Lirong Wu</a>. </li>
<!-- <li><b> <font color="#FF0000">[2021.07]</font> </b> One paper on <i>invertible learning</i> has been accepted by <b>ECML-PKDD2021</b>, congrats to <a href="https://scholar.google.com/citations?user=SKTQTXwAAAAJ&hl=zh-CN" target="_blank" style="color:#2a7ce0">Siyuan Li</a>. </li> -->
<!-- <li><b> <font color="#FF0000">[2020.10]</font> </b> One paper on <i>mass spectrometry</i> has been accepted by <b>JASMS</b>. </li> -->
<!-- <li><b> <font color="#FF0000">[2020.09]</font> </b> One paper on <i>video compression</i> has been accepted by <b>TCSVT</b>. </li> -->
<li><b> <font color="#FF0000">[2020.09]</font> </b> Got my B.S. degree! </li>
<!-- <li><b> <font color="#FF0000">[2019.10]</font> </b> One paper on <i>image compression</i> has been accepted by <b>WACV2020</b>. </li> -->
</ul>
<br />



 
<A NAME="Interest"><h2>Research Interest</h2></A>
Currently, I focus on the Data-efficient Deep Learning:
<ul>
<li>General Data Augmentation</li>
<li>Semi-supervised Learning</li>
<li>Transfer Learning</li>
</ul>
<br />



 
<A NAME="Education"><h2>Education</h2></A>
<ul>
<li>2020.09-present &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D at <a href="https://www.westlake.edu.cn/" target="_blank" style="color:#2a7ce0">CAIRI</a>, <a href="https://www.westlake.edu.cn/" target="_blank" style="color:#2a7ce0">Westlake University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=Y-nyLGIAAAAJ" target="_blank" style="color:#2a7ce0">Stan Z. Li</a></li>
<li>2016.09-2020.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.Sc. at <a href="https://www.liverpool.ac.uk/" target="_blank" style="color:#2a7ce0">University of Liverpool</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://scholar.google.co.uk/citations?user=r6CvuOUAAAAJ&hl=en" target="_blank" style="color:#2a7ce0">Feng Zhao</a></li>
</ul>
<br />

 


<A NAME="Publications"><h2>Publications</h2></A>
<!-- <p><b>Journals</b>: </p>
<font size="3"> 
<ul>

<table class="imgtable"><tr><td>
    <img src="./Files/NCAA_2022_MDGNN_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://link.springer.com/article/10.1007/s00521-022-06930-1" target="_blank" style="color:#2a7ce0">Multi-level disentanglement graph neural network</a></b></font><br>
        <i> <b>Lirong Wu</b>, Haitao Lin, Jun Xia, Cheng Tan, and Stan Z. Li </a></i><br><i><b>Neural Computing and Applications (NCAA)</b></i><br>
        [<a href= "https://link.springer.com/article/10.1007/s00521-022-06930-1" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/LirongWu/MD-GNN" target="_blank" style="color:#2a7ce0">Code</a>]  
        [<a href="./Files/NCAA_2022_MDGNN_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>]
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="./Files/TKDE_2021_GraphSSL_cover.png" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/pdf/2105.07342" target="_blank" style="color:#2a7ce0">Self-supervised Learning on Graphs: Contrastive, Generative,or Predictive</a></b></font><br>
        <i> <b>Lirong Wu</b>, Haitao Lin, Cheng Tan, Zhangyang Gao, and Stan Z. Li </a></i><br><i><b>IEEE Transactions on Knowledge and Data Engineering (TKDE)</b></i><br>
        [<a href= "https://arxiv.org/pdf/2105.07342" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/LirongWu/awesome-graph-self-supervised-learning" target="_blank" style="color:#2a7ce0">Code</a>]  
        [<a href="./Files/TKDE_2021_GraphSSL_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] <br>
        <a class="github-button" href="https://github.com/LirongWu/awesome-graph-self-supervised-learning" data-show-count="true" aria-label="Star LirongWu/awesome-graph-self-supervised-learning on GitHub">Star</a>
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="./Files/JASMS_2021_MS_cover.png" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://pubs.acs.org/doi/pdf/10.1021/jasms.0c00254" target="_blank" style="color:#2a7ce0">Phenotype classification using proteome data in a data-independent acquisition tensor format</a></b></font><br>
        <i> Fangfei Zhang*, Shaoyang Yu*, <b>Lirong Wu</b>*, Zelin Zang, Xiao Yi, , et al. </a></i><br><i><b>Journal of the American Society for Mass Spectrometry (JASMS)</b></i><br>
        [<a href= "https://pubs.acs.org/doi/pdf/10.1021/jasms.0c00254" target="_blank" style="color:#2a7ce0">PDF</a>]  
        [<a href="./Files/JASMS_2021_MS_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="./Files/TCSVT_2021_DVC_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9208694" target="_blank" style="color:#2a7ce0">Foreground-background Parallel Compression with Residual Encoding for Surveillance Video</a></b></font><br>
        <i> <b>Lirong Wu</b>, Kejie Huang, Haibin Shen, Lianli Gao </a></i><br><i><b>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</b></i><br>
        [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9208694" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="./Files/TCSVT_2021_DVC_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table>


</ul>
</font>
<br />
<br />
<br /> -->

 
 
<p><b>Conferences</b>: </p>
<font size="3"> 
<ul>


<!-- <table class="imgtable"><tr><td>
    <img src="./Files/WWW_2022_SimGRACE_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2202.03104" target="_blank" style="color:#2a7ce0">SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation</a></b></font><br>
        <i> Jun Xia*, <b>Lirong Wu</b>*, Jintao Chen, Bozhen Hu, and Stan Z. Li </a></i><br><i><b>WWW, 2022</b></i><br>
        [<a href= "https://arxiv.org/abs/2202.03104" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/junxia97/SimGRACE" target="_blank" style="color:#2a7ce0">Code</a>]
        [<a href="./Files/WWW_2022_SimGRACE_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table> -->

<table class="imgtable"><tr><td>
    <img src="./Files/ECCV_2022_AutoMix_cover.png" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2103.13027" target="_blank" style="color:#2a7ce0">AutoMix: Unveiling the Power of Mixup for Stronger Classifiers</a></b></font><br>
        <i> <b>Zicheng Liu*</b>, Siyuan Li*, Di Wu, Zihan Liu, Zhiyuan Chen, Lirong Wu, and Stan Z. Li </a></i><br><i><b>ECCV, 2022 (<font color="#FF0000">Oral Presentation, rate: 2.7% in all submissions.</font>)</b></i><br>
        [<a href= "https://arxiv.org/abs/2103.13027" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/Westlake-AI/openmixup" target="_blank" style="color:#2a7ce0">Code</a>]
        [<a href="./Files/AAAI_2022_CLCRN_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="./Files/WACV_2022_GCML_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://openaccess.thecvf.com/content/WACV2022/papers/Wu_Generalized_Clustering_and_Multi-Manifold_Learning_With_Geometric_Structure_Preservation_WACV_2022_paper.pdf" target="_blank" style="color:#2a7ce0">Generalized Clustering and Multi-Manifold Learning with Geometric Structure Preservation</a></b></font><br>
        <i>Lirong Wu, <b>Zicheng Liu</b>, Zelin Zang, Jun Xia, Siyuan Li, Stan Z. Li </a></i><br><i><b>WACV, 2022</b></i><br>
        [<a href= "https://openaccess.thecvf.com/content/WACV2022/papers/Wu_Generalized_Clustering_and_Multi-Manifold_Learning_With_Geometric_Structure_Preservation_WACV_2022_paper.pdf" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/LirongWu/GCML" target="_blank" style="color:#2a7ce0">Code</a>] 
        [<a href="./Files/WACV_2022_GCML_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table>

<!-- <table class="imgtable"><tr><td>
    <img src="./Files/ACMMM_2021_Co-learning_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://dl.acm.org/doi/pdf/10.1145/3474085.3475622" target="_blank" style="color:#2a7ce0">Co-learning: Learning from Noisy Labels with Self-supervision</a></b></font><br>
        <i> Cheng Tan*, Jun Xia*, <b>Lirong Wu</b>, Stan Z. Li </a></i><br><i><b>ACM MM, 2021 (<font color="#FF0000">Oral Presentation</font>)</b></i><br>
        [<a href= "https://dl.acm.org/doi/pdf/10.1145/3474085.3475622" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/chengtan9907/Co-training-based_noisy-label-learning" target="_blank" style="color:#2a7ce0">Code</a>] 
        [<a href="./Files/ACMMM_2021_Co-learning_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>]  
</p></td></tr></table> -->

<!-- <table class="imgtable"><tr><td>
    <img src="./Files/ECML_2021_INV_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/pdf/2010.04012" target="_blank" style="color:#2a7ce0">Invertible Manifold Learning for Dimension Reduction</a></b></font><br>
        <i> Siyuan Li, Haitao Lin, Zelin Zang, <b>Lirong Wu</b>, Jun Xia, Stan Z. Li </a></i><br><i><b>ECML-PKDD, 2021</b></i><br>
        [<a href= "https://arxiv.org/pdf/2010.04012" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="https://github.com/Westlake-AI/inv-ML" target="_blank" style="color:#2a7ce0">Code</a>] 
        [<a href="./Files/ECML_2021_INV_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="./Files/WACV_2020_GAN_cover.PNG" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://openaccess.thecvf.com/content_WACV_2020/papers/Wu_A_GAN-based_Tunable_Image_Compression_System_WACV_2020_paper.pdf" target="_blank" style="color:#2a7ce0">A Gan-based Tunable Image Compression System</a></b></font><br>
        <i> <b>Lirong Wu</b>, Kejie Huang, Haibin Shen </a></i><br><i><b>WACV, 2020</b></i><br>
        [<a href= "https://openaccess.thecvf.com/content_WACV_2020/papers/Wu_A_GAN-based_Tunable_Image_Compression_System_WACV_2020_paper.pdf" target="_blank" style="color:#2a7ce0">PDF</a>] 
        [<a href="./Files/WACV_2020_GAN_Slide.pdf" target="_blank" style="color:#2a7ce0">Slide</a>] 
        [<a href="./Files/WACV_2020_GAN_Poster.pdf" target="_blank" style="color:#2a7ce0">Poster</a>] 
        [<a href="https://www.youtube.com/watch?v=hrI-WTrZEgM&t=180s" target="_blank" style="color:#2a7ce0">Video</a>] 
        [<a href="./Files/WACV_2020_GAN_bibtex.html" target="_blank" style="color:#2a7ce0">BibTeX</a>] 
</p></td></tr></table> -->


</ul>
<br />
 


 
<A NAME="Services"><h2>Services</h2></A>
 
<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>IEEE, Student Member, 2022-present</li>
</ul>
</font>
<br />
<br />
 
<p><b>Reviewer</b>: </p>
<font size="3"> 
<ul>
<!-- <li>IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>)</li> -->
<!-- <li>IEEE International Conference on Image Processing (<b>ICIP</b>)</li> -->
<li>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</li>
<li>International Conference on Learning Representations (<b>ICLR</b>)</li>
<li>Conference and Workshop on Neural Information Processing Systems (<b>NIPS</b>)</li>
<li>International Conference on Machine Learning (<b>ICML</b>)</li>
<li>International Joint Conference on Artificial Intelligence (<b>IJCAI</b>)</li>
<li>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</li>
</ul>
</font>
<br />

<!-- 
<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2017, First Prize of Academic Scholarship, Zhejiang University | <font style="font-family:Microsoft YaHei">学业奖学金一等奖</font></li>
</ul>
</font>
 
<br />
<br /> -->


<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5x3ebj080sx&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
 

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


<!--
All Rights Reserved by Lirong Wu. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

<!--
<font size="2"; color="#A0A0A0";>
<p style="text-align:center">Updating time: 2021.09.24</p>
</font>
-->

</body>
</html>
